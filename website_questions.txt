1.  What is the problem you are trying to solve with this application?
	A full resolution image file of a typical Chandra observation using the
	ACIS instrument is 8192x8192 pixels.  Due to time constraints and
	calculation complexities of algorithms that analyze the data, sometimes
	concessions need to be made.  For example, CIAO provides a routine,
	dmimgadapt() (http://goo.gl/qWBqe), that takes an image as input then
	adaptively smooths the image.  It does this by building a 2D box around
	each pixel until a user defined threshold is met, or a user defined max
	box size is encountered.  The complexity of the algorithm in worst case
	scenario is O(n^4).  Thus, with a large image, it can take days to achieve
	the output image. The data is usually scaled, or binned, by a factor
	of 8 in order to obtain a more manageable image size of 1024x1024.
	However, by doing so some of the finer detail of the image is lost.
	With this configuration, a typical file may take 30 minutes to produce
	an output file.  The goal of the project is to modify the dmimgadapt()
	routine from C-code to a more general python implementation.  Then we
	will implement a GPU version of the algorithm.  When finished, we want
	to drastically improve the runtime of the algorithm, via the GPU, and
	test the ability to run the algorithm on a full resolution 8192x8192
	image.


2.  Describe your data in detail: where did it come from, how did you acquire
it, what does it mean, etc.
	The data we are using comes from the publicly available observations of
	the Chandra X-Ray Observatory (http://goo.gl/p6W6v).  Data collected
	from the observatory is considered proprietary for up to one year, then
	the data becomes public.  One of the main methods to access the data is
	through the Chandra Data Archive (http://goo.gl/BYn5i).  In our project
	we used the following Chandra Observations, denoted by Obs ID
	(Observation Identification Number): a. OBSID 114
		Object: CAS A (http://goo.gl/ZVBkC)
	b. OBSID 7417
		Object: Cluster in NGC 2071
	c. OBSID 321
		Object: NGC 4472 = M49 (Galaxy in Virgo)
	d. OBSID 11759
		Object: J0417.5-1154 (Strong lensing cluster)

Obtaining The Data
	On the Chandra Data Archive website (http://goo.gl/ZVBkC) we used the
	OBSID of the above observations in the "Observation ID" field.  Then hit
	search.  This brings up the matching observations.  We then clicked the
	"Primary Products" radio button and then "Add to Retrieval List".  We
	then selected "Retrieve Products".  We then entered my email address to
	be notified when the observation data was available.  When the email
	arrived we followed the instructions on using anonymous ftp and the
	directory location of the data to retrieve the files.  Once I had the
	files we uncompressed the file resulting in a directory with the Obs ID
	and a "primary" subdirectory.  The data files we want are in the
	"primary" directory.  For our project we used the files ending with
	evt2.fits.  These are the primary event data that have gone through two
	levels of automated pipeline processing.  This file contains all of the
	information regarding the data collected by ACIS that we used to create
	our input images.

Preparing The Data
	In order to prepare the data, tools from the CIAO software suite were
	used.  In order to install the software visit the CIAO website
	(http://goo.gl/dsE5M).  The website gives detailed directions for
	downloading and installing the software.

	Steps for Obs ID 321: 
	1.  We wanted to convert the evt2.fits file into
	separate files for each ccd and bin the data by 8 using the dmimg2jpg
	and dmkeypar tools from CIAO to determine which ccds were turned on
	during the observation: (http://goo.gl/V4POS) (http://goo.gl/x25ZH)

	%: dmkeypar "acisf00321N003_evt2.fits.gz" DETNAM echo+ 
	%: ACIS-235678 
	%: dmimg2jpg "acisf00321N003_evt2.fits.gz[ccd_id=2][bin sky=::8]"
		out=321_ccd2.jpg scalefun=log mode=h clob+
	%: dmimg2jpg "acisf00321N003_evt2.fits.gz[ccd_id=3][bin sky=::8]"
		out=321_ccd3.jpg scalefun=log mode=h clob+
	%: dmimg2jpg "acisf00321N003_evt2.fits.gz[ccd_id=5][bin sky=::8]"
		out=321_ccd5.jpg scalefun=log mode=h clob+
	%: dmimg2jpg "acisf00321N003_evt2.fits.gz[ccd_id=6][bin sky=::8]"
		out=321_ccd6.jpg scalefun=log mode=h clob+
	%: dmimg2jpg "acisf00321N003_evt2.fits.gz[ccd_id=7][bin sky=::8]"
		out=321_ccd7.jpg scalefun=log mode=h clob+
	%: dmimg2jpg "acisf00321N003_evt2.fits.gz[ccd_id=8][bin sky=::8]"
		out=321_ccd8.jpg scalefun=log mode=h clob+

	2.  We repeated the conversion for all four of our test Obs IDs.  
	3.  Once we had a directory full of jpg images of all of the ccds for each of
	the observations I did a batch convert to turn them in png files.  We did
	this using the MAC OS tool Automator (http://goo.gl/pGeFB) to do the
	batch convert. These png images then became our input images for our
	python scripts.

3.  Describe your program design and why you chose the features you did.

    Executive Summary:
    
    0. Preprocessing Data
    1. Re-implementing serial version from C into Python
	a. We wanted to use Python for seamless integration with the tools/ideas learned in the course. 
	b. The important features we chose to implement from the dmimgadapt() algorithm were the following:
		+ For each pixel in an input image, find the smallest box such that the sum of the pixels inside the box is at least some user defined threshold value.  If the size of the box reaches a user defined maximum size, we move on to the next pixel.
		+  Using the box size determined from (a), we create a properly normalized output image where the sum(input pixels) = sum(output pixels)
	c. Upon initially looking over the dmimgadapt() tool, we initially thought the serial algorithm would be implemented using MPI techniques similar to the Wave Equation Problem encountered in our HW3 problem set.  But after further review of the algorithm, we noticed that the pixel values are static and therefore landed itself to GPU implementation.  
        d. We had to have 3 for-loop kernels to match dmimgadapt() source code. The Gaussian weights were relatively easy to implement in python in lines x and y of 'image_adapt_serial_gaussian.py.'
    
    2. Implementing GPU version
        
        a. Implemented 3 kernels, minimized CPU to GPU read/writes but having all
            kernels access the same global memory and calculate using shared memory
        b. Gaussian is very difficult to implement and has been deferred
        c. 


4.  How do you use your application (mouse and keyboard functions, input/output,
etc)?
	Serial Version:
	In order to run the serial version we ended up having to hard code some of the user defined values as there seemed to be an issue reading in command line arguments on the Resonance Cluster.  
	So near the top of the file is the 'file_name' variable we use to to specify which image we wish to run through the algorithm.  
	We then have our 'Threshold' and 'MaxRad' variables.  These are the user defined variables that specify the value of the pixels in the created box, Threshold, and the maximum size box to attempt to reach the threshold value, MaxRad.  
	The output image is created in the same directory as the input image.  We remove the extension of the input file and then append '_smoothed_serial.png' to name.  
	While running our program on the Resonance cluster:
	%: gpu-login
	%: cd to base directory of our project
	%: python image_adapt_serial_norm.py

	GPU Version:


5.  What is the performance of your code? What speedup and efficiency did you
achieve? What optimizations did you implement to achieve this speedup?

6.  What interesting insights did you gain from this project?
	Danny:
	I know have a deeper understanding of the dmimgadapt() CIAO tool.  Before this project I had never used it before at work.  I now see the great benefits of using GPUs to analyze real life data.  When I enrolled in this course I wasn't exactly sure how it would translate to the types of data I deal with and algorithms we implement at work, now I see how much more quickly and efficiently things can be handled with parallel processing.  Whether it comes in the form of GPU or MPI, there is great benefit from utilizing these approaches in the astronomy field.   

	Chris:
	Insights are...

7.  What extensions and improvements can you suggest?
	While implementing the project we ran into difficulty implementing a weighted sum approach.  We had a serial version coded up utilizing a gaussian weighted sum, then when we were coding the parallel version we ran into difficulties.  What took two lines to achieve in Python, was seemingly going to take 15-20 lines.  So we deferred that as an item we would like to implement given more time.  In addition to the gaussian weighted sum, there are other methods we could implement, like cone, boxcar, tophat, or mexican hat weighted sum approaches.  
	In order to make the input files easier for us to deal with in python and with the installed packages on Resonance, we decided to convert the astronomical data from fits files ultimately to png files.  An improvement we could deliver would be to handle the fits file format directly, read in the data, perform our adaptive smoothing algorithm, then write out a new fits file.  This would also allow for a more one to one comparison between the C code implementation from CIAO tools to the Python implementation we used.
	The original C implementation has the option to output some of the intermediate data files.  The user can specify to output a file of all of the sum values, a file of all the normalization values and also all the radius/box size values.  
	The ultimate goal of the project would be to incorporate it into the CIAO data model.  This would allow for seamless integration into data analysis for x-ray astronomers with access to a GPU.  The CIAO Data Model (DM) is a versatile interface used by CIAO to examine and manipulate standard format data files (e.g Fits, ascii).  (http://goo.gl/QMXx0)  This would greatly reduce the time for data analysis.
	 

8.  What did you most enjoy about working on this project? What was the most
challenging aspect? What was the most frustrating? What would you do differently
next time?
	Danny:
	I enjoyed being able to apply the concepts learned in the course to things I see at work.  Many times in past courses I have taken, the projects end up being more of an academic exercise than real life applications.  I see now why the instructors requesting people pick something they found interesting to work on because I did spent a lot of time on it and it was nice to know I can apply this knowledge to future projects outside of the course environment.  
	The most challenging aspect for me was to translate the existing C code with all of the specific "CIAOisms" and create a Python version of the code.  Luckily, my boss, Kenny Glotfelty, provided a basic pseudo code representation of the algorithm.  However, there were still challenges creating a pythonic version of a c algorithm.  I am sure there are more pythonic ways to do some of the computations we ended up doing.  So part of the frustration was learning the ins and outs of Python and realizing that somethings are not meant to have a direct c to python conversion.  There are times when Python does things differently and it took time to learn and figure out what those things are.  
	One of the most frustrating things that I came across ended up being a simple issue of the type of input file we were using.  CIAO provided us a tool called dmimg2jpg, so I used that to create what I thought was a useful input jpg image.  I thought I had the serial version of the code working wonderfully but ended up with a terrible output image.  So I went through the algorithm line by line.  When I got to the top I thought that surely the input file must be ok, but they way I was reading the file, the type I needed was a png file, the jpg version was not giving the same values as the png version.  So many hours were spent looking into the problem and many tears of joy occurred when the solution was found.  It always seems that the hardest bugs are the smallest ones at the end to diagnose and deal with.  
	I think the thing that I would do differently next time would be to have a better overall understanding of the project I was dealing with going into it.  I didn't realize the complexity of the original algorithm and assumed the time window we had for the final project was ample time to work through it all.  Had I known the specific complexities of dealing with C and Python in the same time, I think I might not have bitten of more than I could chew.  I think I also would have spent more time at the beginning getting things set up to use the fits file format so we would have had the exact same data to work with as the C program.  Then we could have had a direct comparison between the C algorithm and the GPU algorithm, instead of a more generic Python version of the algorithm.   

	Chris:
	Enoyed...
